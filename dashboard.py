import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import time
import json
import os
import random
import numpy as np
import io
import subprocess
import sys
from datetime import datetime, timedelta
import calendar 
from bs4 import BeautifulSoup
import urllib.parse
import csv
import requests

# [ë¼ì´ë¸ŒëŸ¬ë¦¬ ì•ˆì „ ì„í¬íŠ¸]
try:
    from openai import OpenAI
except ImportError:
    pass

# -----------------------------------------------------------------------------
# 0. Page Configuration & CSS Styling
# -----------------------------------------------------------------------------
st.set_page_config(page_title="NOT FOUND Security Dashboard", layout="wide")

# [Custom CSS]
st.markdown("""
    <style>
    /* ì „ì²´ í°íŠ¸ ë° ë°°ê²½ */
    .stApp {
        background-color: #FFFFFF;
        color: #333333;
        font-family: 'Roboto', 'Helvetica Neue', Arial, sans-serif;
    }
    
    /* í…ìŠ¤íŠ¸ ìƒ‰ìƒ */
    h1, h2, h3, h4, h5, h6, p, div, span, label, li {
        color: #333333 !important;
        font-weight: normal !important;
    }
    
    /* ìˆ«ì ë©”íŠ¸ë¦­ ìŠ¤íƒ€ì¼ */
    [data-testid="metric-container"]:nth-child(2) [data-testid="stMetricValue"] {
        color: #D32F2F !important; /* Criticalë§Œ ë¹¨ê°• */
    }
    [data-testid="stMetricValue"] {
        color: #424242 !important; /* ë‚˜ë¨¸ì§€ëŠ” ì§„í•œ íšŒìƒ‰ */
        font-weight: normal !important;
    }
    
    /* ì»¨í…Œì´ë„ˆ ë° Expander ìŠ¤íƒ€ì¼ */
    .block-container { padding-top: 2rem; }
    div[data-testid="stExpander"] {
        border: 1px solid #E0E0E0;
        background-color: #FFFFFF;
        border-radius: 6px;
        box-shadow: none;
        margin-bottom: 10px;
    }
    
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    button[kind="primary"] {
        background-color: #D32F2F;
        border: none;
        color: white !important;
    }
    
    /* í‚¤ì›Œë“œ íƒœê·¸ ìŠ¤íƒ€ì¼ */
    .keyword-tag-critical {
        background-color: #D32F2F;
        color: white !important;
        padding: 5px 12px;
        border-radius: 15px;
        margin: 3px;
        display: inline-block;
        font-size: 14px;
    }
    .keyword-tag-high {
        background-color: #FBC02D;
        color: #333333 !important;
        padding: 5px 12px;
        border-radius: 15px;
        margin: 3px;
        display: inline-block;
        font-size: 14px;
        font-weight: bold !important;
    }
    </style>
    """, unsafe_allow_html=True)

# -----------------------------------------------------------------------------
# 1. Constants & Settings
# -----------------------------------------------------------------------------
SEVERITY_COLORS = {
    "Critical": "#D32F2F", # Red
    "High": "#FBC02D",     # Yellow
    "Medium": "#9E9E9E",   # Medium Gray
    "Low": "#E0E0E0"       # Light Gray
}

STATUS_COLORS = {
    "Open": "#D32F2F",       # Red
    "In Progress": "#FBC02D",# Yellow
    "Resolved": "#757575",   # Dark Gray
    "Risk Accepted": "#BDBDBD" # Light Gray
}

# Global NVD Top 10 (Mock Data for Comparison Reference)
GLOBAL_TOP_10 = [
    {"id": "CVE-2011-2523", "desc": "Vsftpd Backdoor"},
    {"id": "CVE-2021-44228", "desc": "Log4Shell"},
    {"id": "CVE-2017-0144", "desc": "EternalBlue"},
    {"id": "CVE-2020-1472", "desc": "Zerologon"},
    {"id": "CVE-2007-2447", "desc": "Samba Usermap"},
    {"id": "CVE-2019-11510", "desc": "Pulse Secure VPN"},
    {"id": "CVE-2010-2075", "desc": "UnrealIRCd"},
    {"id": "CVE-2023-32971", "desc": "Apache TomCat Info"},
    {"id": "CVE-2022-26134", "desc": "Confluence OGNL"},
    {"id": "CVE-2014-0160", "desc": "Heartbleed"}
]

EXPLOIT_EPSS_THRESHOLD = 0.6

EXPLOIT_SCENARIOS = {
    "CVE-2011-2523": {"name": "Vsftpd Backdoor", "logs": ["Connecting...", "Root shell opened"], "desc": "vsftpd 2.3.4 backdoor."},
    "CVE-2007-2447": {"name": "Samba Usermap", "logs": ["Payload sent...", "Command executed"], "desc": "Samba remote execution."},
    "CVE-2010-2075": {"name": "UnrealIRCd Backdoor", "logs": ["Triggering...", "Shell spawned"], "desc": "UnrealIRCd backdoor."}
}

SCANNER_SCRIPT_NAME = "main.py"

# -----------------------------------------------------------------------------
# 2. Utility Functions (Real Data Only)
# -----------------------------------------------------------------------------
@st.cache_data
def load_data(uploaded_file_content=None):
    """
    - êµ¬í¬ë§·: {"results": [ {service, version, port, cves:[...]} ]}
    - ì‹ í¬ë§·: {"target": "...", "services": [ {port, service, version, enum:{cve_search:{cves:[...]}} } ]}
    ë¥¼ ëª¨ë‘ ì§€ì›í•œë‹¤.
    """
    raw_data = None

    # 1) ì—…ë¡œë“œëœ íŒŒì¼ì´ ìˆìœ¼ë©´ ê·¸ê±¸ ë¨¼ì € ì‚¬ìš©
    if uploaded_file_content:
        try:
            uploaded_file_content.seek(0)
            content = uploaded_file_content.read().decode('utf-8')
            raw_data = json.loads(content)
        except Exception:
            return pd.DataFrame()
    else:
        # 2) ê¸°ë³¸ íŒŒì¼ ê²½ë¡œ (recon_result.json)
        file_path = 'recon_result.json'
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    raw_data = json.load(f)
            except Exception:
                return pd.DataFrame()
        else:
            return pd.DataFrame()

    if not raw_data:
        return pd.DataFrame()

    # ì–´ë–¤ í¬ë§·ì¸ì§€ íŒë³„
    if 'results' in raw_data:
        records = raw_data['results']
        mode = 'results'
    elif 'services' in raw_data:
        records = raw_data['services']
        mode = 'services'
    else:
        # ì•Œ ìˆ˜ ì—†ëŠ” í¬ë§·
        return pd.DataFrame()

    processed_list = []

    for result in records:
        if mode == 'results':
            service_name = result.get('service', 'Unknown')
            version_name = result.get('version', 'Unknown')
            port = result.get('port', '0')
            cves = result.get('cves', [])
        else:  # mode == 'services'
            service_name = result.get('service', 'Unknown')
            version_name = result.get('version', 'Unknown')
            port = result.get('port', '0')

            enum = result.get('enum') or {}
            cve_block = enum.get('cve_search') or {}
            cves = cve_block.get('cves', [])

        if not cves:
            continue

        product_label = f"{service_name} ({version_name})"

        for cve in cves:
            cve_id = cve.get('id', 'Unknown')
            cvss = cve.get('score', 0.0)
            summary = cve.get('summary', 'No description.')

            # epss ìˆìœ¼ë©´ ì“°ê³ , ì—†ìœ¼ë©´ 0
            real_epss = cve.get('epss')
            epss = float(real_epss) if real_epss is not None else 0.0

            try:
                year = int(cve_id.split('-')[1])
            except Exception:
                year = 2025

            if cvss >= 9.0:
                severity = "Critical"
            elif cvss >= 7.0:
                severity = "High"
            elif cvss >= 4.0:
                severity = "Medium"
            else:
                severity = "Low"

            # ë°ëª¨ìš© ë‚ ì§œ ìƒì„± (í¬íŠ¸+CVSSë¡œ seed ì¤˜ì„œ ì¬í˜„ ê°€ëŠ¥)
            try:
                seed_val = int(port) + int(float(cvss) * 100)
                random.seed(seed_val)
            except Exception:
                random.seed(42)

            base_year = 2025
            day_offset = random.randint(0, 364)
            detect_date = datetime(base_year, 1, 1) + timedelta(days=day_offset)

            processed_list.append({
                "CVE_NAME": cve_id,
                "PORT": port,
                "PRODUCT_NAME": product_label,
                "SERVICE_TYPE": service_name,
                "CVSS_SCORE": float(cvss) if cvss else 0.0,
                "EPSS_SCORE": epss,
                "SEVERITY": severity,
                "EXPLOIT_STATUS": epss >= EXPLOIT_EPSS_THRESHOLD,
                "PUBLISH_YEAR": year,
                "DESCRIPTION": summary,
                "DETECT_DATE": detect_date,
                "DETECT_DATE_STR": detect_date.strftime("%Y-%m-%d"),
                "YEAR": detect_date.year,
                "IS_DETECTED": True,
                "NVD_SEARCHES": random.randint(100, 1000),
            })

    return pd.DataFrame(processed_list)

EXPLOITDB_CSV_URL = "https://gitlab.com/exploit-database/exploitdb/-/raw/main/files_exploits.csv"

@st.cache_data(show_spinner=False)
def _load_exploitdb_index() -> list[dict]:
    """
    Exploit-DB GitLabì—ì„œ files_exploits.csvë¥¼ ë°›ì•„ì™€
    Dict ë¦¬ìŠ¤íŠ¸ë¡œ ìºì‹œí•´ ë‘”ë‹¤.
    """
    resp = requests.get(EXPLOITDB_CSV_URL, timeout=20)
    resp.raise_for_status()  # 200ì´ ì•„ë‹ˆë©´ ì˜ˆì™¸

    # CSV í…ìŠ¤íŠ¸ â†’ DictReader
    buf = io.StringIO(resp.text)
    reader = csv.DictReader(buf)
    rows = [row for row in reader]
    return rows


@st.cache_data(show_spinner=False)
def fetch_exploitdb_for_cve(cve_id: str):
    """
    CSV ì¸ë±ìŠ¤ë¥¼ ì´ìš©í•´ íŠ¹ì • CVEê°€ ë“¤ì–´ìˆëŠ” Exploit-DB ë ˆì½”ë“œë¥¼ ì°¾ëŠ”ë‹¤.

    ë°˜í™˜: [ {edb_id, title, url, date, verified}, ... ]
    """
    cve = cve_id.upper().strip()
    rows = _load_exploitdb_index()

    results: list[dict] = []
    for r in rows:
        codes = (r.get("codes") or "").upper()
        if cve not in codes:
            continue

        edb_id = (r.get("id") or r.get("EDB-ID") or "").strip()
        if not edb_id:
            continue

        title = (r.get("description") or "").strip()
        date_text = (r.get("date") or "").strip()

        # verified ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ëŒ€ì¶© í•´ì„í•´ì„œ boolë¡œ
        verified_raw = (r.get("verified") or "").strip().lower()
        verified = verified_raw in ("1", "true", "yes", "y", "âœ”", "âœ“")

        url = f"https://www.exploit-db.com/exploits/{edb_id}"

        results.append(
            {
                "edb_id": edb_id,
                "title": title,
                "url": url,
                "date": date_text,
                "verified": verified,
            }
        )

    return results

def get_top_keywords(df):
    import re
    from collections import Counter
    text = " ".join(df['DESCRIPTION'].astype(str).tolist()).lower()
    words = re.findall(r'\b[a-z]{4,15}\b', text)
    stopwords = {'allow', 'remote', 'attackers', 'user', 'service', 'arbitrary', 'code', 'execution', 'vulnerability', 'via', 'this', 'that', 'with', 'from', 'version', 'earlier', 'before', 'allows', 'support', 'properly'}
    filtered_words = [w for w in words if w not in stopwords]
    return Counter(filtered_words).most_common(12)

def to_excel(df):
    output = io.BytesIO()
    try:
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df.to_excel(writer, index=False, sheet_name='Sheet1')
    except ImportError:
        return None
    return output.getvalue()

def run_scanner_script():
    if not os.path.exists(SCANNER_SCRIPT_NAME):
        st.error(f"Scanner script '{SCANNER_SCRIPT_NAME}' not found.")
        return False
    try:
        result = subprocess.run([sys.executable, SCANNER_SCRIPT_NAME], capture_output=True, text=True)
        if result.returncode == 0:
            return True
        else:
            st.error(f"Scanner failed: {result.stderr}")
            return False
    except Exception as e:
        st.error(f"Error executing scanner: {e}")
        return False

# -----------------------------------------------------------------------------
# 3. Sidebar
# -----------------------------------------------------------------------------
if 'df' not in st.session_state:
    st.session_state['df'] = load_data()
    st.session_state['plan_data'] = pd.DataFrame()
if 'selected_cves' not in st.session_state:
    st.session_state['selected_cves'] = []
if 'last_uploaded_file' not in st.session_state:
    st.session_state['last_uploaded_file'] = None

# Init Plan Data
if not st.session_state['df'].empty and st.session_state['plan_data'].empty:
    plan_init = st.session_state['df'][['CVE_NAME', 'PRODUCT_NAME', 'CVSS_SCORE', 'SEVERITY']].copy()
    plan_init['Status'] = 'Open'
    plan_init['Priority'] = 'Medium'
    plan_init['Owner'] = 'Security Team'
    plan_init['Note'] = ''
    st.session_state['plan_data'] = plan_init

uploaded_file = st.sidebar.file_uploader("Upload JSON", type=['json'], help="ìŠ¤ìº”ëœ ê²°ê³¼ JSON íŒŒì¼ì„ ì´ê³³ì— ì—…ë¡œë“œí•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
if uploaded_file is not None:
    file_id = f"{uploaded_file.name}_{uploaded_file.size}"
    if st.session_state['last_uploaded_file'] != file_id:
        with st.spinner("Analyzing..."):
            st.cache_data.clear()
            new_df = load_data(uploaded_file_content=uploaded_file)
            if not new_df.empty:
                st.session_state.df = new_df
                st.session_state.plan_data = pd.DataFrame()
                st.session_state['last_uploaded_file'] = file_id
                st.rerun()

with st.sidebar:
    st.caption("Ver 57.1 (Graph Size Fix & Immediate Search)")
    
    openai_api_key = st.text_input("OpenAI API Key", type="password", help="AI ë¶„ì„ ê¸°ëŠ¥(Ask AI Analyst) ì‚¬ìš© ì‹œ í•„ìš”í•œ API í‚¤ì…ë‹ˆë‹¤.")

    st.markdown("---")
    
    if not st.session_state.df.empty:
        start_date = st.session_state.df['DETECT_DATE'].min().date()
        end_date = st.session_state.df['DETECT_DATE'].max().date()
    else:
        start_date = datetime.now().date()
        end_date = datetime.now().date()
        
    st.subheader("Scanner Settings", help="ì·¨ì•½ì  ìŠ¤ìº” ëª¨ë“œë¥¼ ì„ íƒí•©ë‹ˆë‹¤.")
    scan_mode = st.radio("Scan Mode", ["Virtual Demo", "Real Scan"], horizontal=True)
    
    if scan_mode == "Virtual Demo":
        if st.button("Run Demo Scan", use_container_width=True, help="ê°€ìƒì˜ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€ì‹œë³´ë“œ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."):
            st.cache_data.clear()
            st.session_state.df = load_data() 
            st.session_state.plan_data = pd.DataFrame()
            st.rerun()
    else:
        c1, c2 = st.columns(2)
        with c1:
            if st.button("Ubuntu", help="ìš°ë¶„íˆ¬ í™˜ê²½ì—ì„œ ì‹¤ì œ ìŠ¤ìºë„ˆë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."): 
                with st.spinner("Scanning..."):
                    if run_scanner_script():
                        st.cache_data.clear()
                        st.session_state.df = load_data()
                        st.success("Complete!")
                        time.sleep(1)
                        st.rerun()
        with c2:
            if st.button("Windows", help="ìœˆë„ìš° í™˜ê²½ì—ì„œ ì‹¤ì œ ìŠ¤ìºë„ˆë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."): 
                with st.spinner("Scanning..."):
                    if run_scanner_script():
                        st.cache_data.clear()
                        st.session_state.df = load_data()
                        st.success("Complete!")
                        time.sleep(1)
                        st.rerun()

    st.markdown("---")
    
    # [ìˆ˜ì •] Search Helperë¥¼ Placeholderë¡œ ë¯¸ë¦¬ ê³µê°„ë§Œ í™•ë³´
    # ì´ë ‡ê²Œ í•˜ë©´ Main UIì—ì„œ ë°ì´í„° ì„ íƒ ì‹œ ë°”ë¡œ ì´ ê³µê°„ì„ ì—…ë°ì´íŠ¸í•˜ì—¬ ë”œë ˆì´ ì—†ì´ í‘œì‹œ ê°€ëŠ¥
    search_helper_ph = st.empty()

    st.markdown("---")
    st.subheader("Filters", help="ìœ„í—˜ë„ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤.")
    current_df = st.session_state.df
    selected_severity = st.multiselect("Severity", ['Critical', 'High', 'Medium', 'Low'], default=['Critical', 'High'])
    
    if not current_df.empty:
        filtered_df = current_df[
            (current_df['SEVERITY'].isin(selected_severity)) &
            (current_df['DETECT_DATE'].dt.date >= start_date) &
            (current_df['DETECT_DATE'].dt.date <= end_date)
        ]
    else:
        filtered_df = pd.DataFrame()

# -----------------------------------------------------------------------------
# 4. Main Dashboard UI
# -----------------------------------------------------------------------------
st.markdown("<h1 style='margin-bottom:0;'>NOT FOUND Integrated Dashboard</h1>", unsafe_allow_html=True)
st.caption("Security Insight: í˜„ì¬ ë³´ì•ˆ ìƒíƒœì— ëŒ€í•œ ì§ê´€ì ì¸ ìš”ì•½ì…ë‹ˆë‹¤.")

if filtered_df.empty:
    st.warning(f"No data loaded. Please run a scan or check your filters.")
    st.stop()

# --- KPI & Keywords ---
col_kpi, col_chart = st.columns([1, 1])
with col_kpi:
    st.markdown("### Executive Summary", help="ì „ì²´ ì·¨ì•½ì  í˜„í™©ì„ ìš”ì•½í•˜ì—¬ ë³´ì—¬ì£¼ëŠ” í•µì‹¬ ì§€í‘œ(KPI)ì…ë‹ˆë‹¤.")
    c1, c2 = st.columns(2)
    
    c1.metric("Total Vulnerabilities", f"{len(filtered_df)}", help="ë°œê²¬ëœ ì´ ì·¨ì•½ì  ìˆ˜ì…ë‹ˆë‹¤.")
    c2.metric("Critical Risks", f"{filtered_df[filtered_df['SEVERITY']=='Critical'].shape[0]}", help="ì¦‰ì‹œ ì¡°ì¹˜ê°€ í•„ìš”í•œ ì¹˜ëª…ì  ìœ„í—˜ ê°œìˆ˜ì…ë‹ˆë‹¤.")
    
    c3, c4 = st.columns(2)
    c3.metric("Exploitable", f"{filtered_df['EXPLOIT_STATUS'].sum()}", help="ê³µê²© ì½”ë“œê°€ ì¡´ì¬í•˜ì—¬ ì•…ìš© ê°€ëŠ¥í•œ ì·¨ì•½ì  ìˆ˜ì…ë‹ˆë‹¤.")
    c4.metric("Avg CVSS", f"{filtered_df['CVSS_SCORE'].mean():.1f}", help="ì „ì²´ ì·¨ì•½ì ì˜ í‰ê·  ìœ„í—˜ ì ìˆ˜ì…ë‹ˆë‹¤.")

with col_chart:
    st.markdown("### Vulnerability Main Themes", help="ì·¨ì•½ì  ì„¤ëª…ì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ” í•µì‹¬ ë‹¨ì–´ë¥¼ ì¶”ì¶œí•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    with st.expander("ì‚¬ìš© ê°€ì´ë“œ ë° ë¶„ì„ íŒ"):
        st.write("ì´ ì„¹ì…˜ì€ ìŠ¤ìº”ëœ ì„œë²„ì˜ ì£¼ìš” ì·¨ì•½ì  í‚¤ì›Œë“œë¥¼ ì§ê´€ì ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤. ë¶‰ì€ìƒ‰ íƒœê·¸ëŠ” ê°€ì¥ ë¹ˆë²ˆí•˜ê²Œ ë°œê²¬ëœ í•µì‹¬ ë¬¸ì œì…ë‹ˆë‹¤.")

    keywords = get_top_keywords(filtered_df)
    if keywords:
        html_content = "<div>"
        max_count = keywords[0][1] if keywords else 1
        for word, count in keywords:
            if count > max_count * 0.5:
                html_content += f"<span class='keyword-tag-critical'>{word} ({count})</span>"
            else:
                html_content += f"<span class='keyword-tag-high'>{word} ({count})</span>"
        html_content += "</div>"
        st.markdown(html_content, unsafe_allow_html=True)

st.markdown("---")

# --- Tabs ---
tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
    "Dashboard", "Calendar", "Statistics", "Comparison", "Deep Analysis", "Remediation", "FAQ"
])

# TAB 1: Dashboard
with tab1:
    st.subheader("Interactive Analysis", help="ë°ì´í„°ë¥¼ ë‹¤ê°ë„ë¡œ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ë©”ì¸ ëŒ€ì‹œë³´ë“œì…ë‹ˆë‹¤.")
    
    # 1. Table
    selection = st.dataframe(
        filtered_df[['CVE_NAME', 'PRODUCT_NAME', 'SEVERITY', 'CVSS_SCORE', 'EPSS_SCORE', 'DETECT_DATE_STR']],
        use_container_width=True, hide_index=True, on_select="rerun", selection_mode="multi-row"
    )
    
    # Data Selection Logic
    selected_cves = []
    if selection.selection.rows:
        for idx in selection.selection.rows:
            selected_cves.append(filtered_df.iloc[idx]['CVE_NAME'])
        st.session_state.selected_cves = selected_cves
    else:
        st.session_state.selected_cves = []
        
    # [ìˆ˜ì •] Immediate Sidebar Update
    # í‘œì—ì„œ ì„ íƒì´ ë°œìƒí•˜ìë§ˆì ì‚¬ì´ë“œë°”ì˜ Placeholderë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    with search_helper_ph.container():
        st.subheader("Search Helper", help="ì„ íƒí•œ CVEë¥¼ êµ¬ê¸€ì—ì„œ ë°”ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
        if st.session_state.selected_cves:
            last = st.session_state.selected_cves[-1]
            st.link_button(f"Search: {last}", f"https://www.google.com/search?q={last} vulnerability exploit")
        else:
            st.caption("ëª©ë¡ì—ì„œ í•­ëª©ì„ ì„ íƒí•˜ì„¸ìš”.")
    
    # 2. Line Chart
    st.markdown("#### Overall Trend", help="ì—°ë„ë³„ ì·¨ì•½ì  ë°œìƒ ì¶”ì´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ê³¼ê±° ë ˆê±°ì‹œ ë¬¸ì œì¸ì§€ ìµœì‹  ìœ„í˜‘ì¸ì§€ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    yearly = filtered_df.groupby(['PUBLISH_YEAR', 'SEVERITY']).size().reset_index(name='COUNT')
    fig_line = px.line(
        yearly, x="PUBLISH_YEAR", y="COUNT", color="SEVERITY",
        color_discrete_map=SEVERITY_COLORS, markers=True
    )
    if selected_cves:
        selected_years = filtered_df[filtered_df['CVE_NAME'].isin(selected_cves)]['PUBLISH_YEAR'].unique()
        for yr in selected_years:
            fig_line.add_vline(x=yr, line_dash="dot", line_color="#333333", opacity=0.5)
    fig_line.update_traces(line=dict(width=3))
    fig_line.update_layout(height=300, paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')
    st.plotly_chart(fig_line, use_container_width=True)

    # 3. Main Charts (Risk Matrix & New Upward Graph)
    c_left, c_right = st.columns(2)
    with c_left:
        st.markdown("#### Risk Matrix", help="ìœ„í—˜ë„(CVSS)ì™€ ê³µê²©í™•ë¥ (EPSS)ì˜ ìƒê´€ê´€ê³„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ìš°ìƒë‹¨ì— ìœ„ì¹˜í• ìˆ˜ë¡ ìœ„í—˜í•©ë‹ˆë‹¤.")
        fig_sc = px.scatter(
            filtered_df, x="CVSS_SCORE", y="EPSS_SCORE", color="SEVERITY",
            color_discrete_map=SEVERITY_COLORS,
            hover_data=['CVE_NAME'], opacity=0.7
        )
        fig_sc.update_traces(marker=dict(size=8, line=dict(width=0)))
        if selected_cves:
            h_df = filtered_df[filtered_df['CVE_NAME'].isin(selected_cves)]
            if not h_df.empty:
                fig_sc.add_trace(go.Scatter(
                    x=h_df['CVSS_SCORE'], y=h_df['EPSS_SCORE'],
                    mode='markers', 
                    marker=dict(size=15, color='rgba(0,0,0,0)', line=dict(color='#333333', width=3)),
                    showlegend=False, hoverinfo='skip'
                ))
        fig_sc.add_vline(x=7.0, line_dash="dash", line_color="#E0E0E0")
        fig_sc.update_layout(height=400)
        st.plotly_chart(fig_sc, use_container_width=True)
        
    with c_right:
        st.markdown("#### Real Risk Assessment", help="CVSS ì ìˆ˜ì™€ EPSS(ê³µê²© í™•ë¥ )ë¥¼ ê²°í•©í•œ ì‹¤ì§ˆì  ìœ„í—˜ë„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. (CVSS * EPSS * 100)")
        
        filtered_df['RISK_SCORE'] = filtered_df['CVSS_SCORE'] * filtered_df['EPSS_SCORE'] * 100
        
        # [ìˆ˜ì •] ì  í¬ê¸°(size)ë¥¼ 8 -> 5ë¡œ ì¶•ì†Œ, Opacity 0.6ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ê²¹ì¹¨ ë°©ì§€
        fig_up = px.scatter(
            filtered_df, x="CVSS_SCORE", y="RISK_SCORE", color="SEVERITY",
            color_discrete_map=SEVERITY_COLORS,
            hover_data=['CVE_NAME'], opacity=0.6,
            labels={"RISK_SCORE": "Real Risk Score (CVSS x EPSS x 100)"}
        )
        fig_up.update_traces(marker=dict(size=5, line=dict(width=0)))
        
        # Highlight logic
        if selected_cves:
            h_df = filtered_df[filtered_df['CVE_NAME'].isin(selected_cves)]
            if not h_df.empty:
                fig_up.add_trace(go.Scatter(
                    x=h_df['CVSS_SCORE'], y=h_df['RISK_SCORE'],
                    mode='markers', 
                    marker=dict(size=15, color='rgba(0,0,0,0)', line=dict(color='#333333', width=3)),
                    showlegend=False, hoverinfo='skip'
                ))
        fig_up.update_layout(height=400)
        st.plotly_chart(fig_up, use_container_width=True)

    st.markdown("---")
    st.markdown("#### Severity Breakdown", help="ë°œê²¬ëœ ì·¨ì•½ì ë“¤ì˜ ìœ„í—˜ë„ë³„ ë¹„ìœ¨ì„ ë„ë„› ì°¨íŠ¸ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    sev_counts = filtered_df['SEVERITY'].value_counts().reset_index()
    sev_counts.columns = ['Severity', 'Count']
    
    fig_donut = px.pie(
        sev_counts, values='Count', names='Severity', hole=0.6,
        color='Severity', color_discrete_map=SEVERITY_COLORS
    )
    fig_donut.update_traces(textinfo='percent+label', textfont_size=14)
    fig_donut.update_layout(height=400, showlegend=True)
    st.plotly_chart(fig_donut, use_container_width=True)
    
    # 4. Service Trend
    st.markdown("#### Service Trends", help="ì–´ë–¤ ì„œë¹„ìŠ¤ì—ì„œ ì·¨ì•½ì ì´ ë§ì´ ë°œìƒí•˜ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤. ì‹œê°„ íë¦„ì— ë”°ë¥¸ ë³€í™”ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    service_trend = filtered_df.groupby(['SERVICE_TYPE', 'PUBLISH_YEAR']).size().reset_index(name='COUNT')
    fig_small = px.area(
        service_trend, x="PUBLISH_YEAR", y="COUNT", 
        facet_col="SERVICE_TYPE", facet_col_wrap=6,
        color_discrete_sequence=['#757575'], 
        height=300
    )
    fig_small.update_layout(
        paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)',
        showlegend=False, margin=dict(t=30, l=0, r=0, b=0)
    )
    fig_small.for_each_annotation(lambda a: a.update(text=a.text.split("=")[-1]))
    st.plotly_chart(fig_small, use_container_width=True)

# TAB 2: Calendar
with tab2:
    st.header(f"Monthly Vulnerability Calendar ({start_date} ~ {end_date})", help="ì›”ë³„ë¡œ ì·¨ì•½ì  ë°œê²¬ í˜„í™©ì„ ë‹¬ë ¥ í˜•íƒœì˜ íˆíŠ¸ë§µê³¼ ëª©ë¡ìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤.")
    st.caption("â„¹ï¸ ëª©ë¡ì„ í´ë¦­í•˜ë©´ ë‹¬ë ¥ì— í…Œë‘ë¦¬ê°€ ìƒê¹ë‹ˆë‹¤.")

    cal_base_df = filtered_df.copy()
    cal_base_df['Month_No'] = cal_base_df['DETECT_DATE'].dt.month
    cal_base_df['Day'] = cal_base_df['DETECT_DATE'].dt.day

    months_list = ["January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December"]
    
    for m_idx, m_name in enumerate(months_list):
        current_month_no = m_idx + 1
        m_df = cal_base_df[cal_base_df['Month_No'] == current_month_no].sort_values('Day').reset_index(drop=True)
        count_in_month = len(m_df)
        
        with st.expander(f"{m_name} ({count_in_month} Items)", expanded=(m_idx == 0)):
            if count_in_month == 0:
                st.info("No vulnerabilities detected this month.")
            else:
                c_cal, c_list = st.columns([1, 1])
                
                target_year = start_date.year
                _, num_days = calendar.monthrange(target_year, current_month_no)
                days_grid = []
                day_counts = m_df['Day'].value_counts().to_dict()
                
                week_num = 0
                for d in range(1, num_days + 1):
                    wd = calendar.weekday(target_year, current_month_no, d)
                    val = day_counts.get(d, 0)
                    days_grid.append({'Day': d, 'Week': week_num, 'Weekday': wd, 'Count': val})
                    if wd == 6: week_num += 1
                grid_df = pd.DataFrame(days_grid)

                list_key = f"list_{m_name}"
                cal_key = f"cal_{m_name}"

                clicked_day_from_cal = None
                if cal_key in st.session_state and st.session_state[cal_key].selection['points']:
                    p = st.session_state[cal_key].selection['points'][0]
                    try:
                        sel_wd, sel_w = p['x'], p['y']
                        row_match = grid_df[(grid_df['Weekday'] == sel_wd) & (grid_df['Week'] == sel_w)]
                        if not row_match.empty:
                            clicked_day_from_cal = row_match.iloc[0]['Day']
                    except: pass
                
                with c_list:
                    st.markdown("###### Vulnerability List")
                    
                    def highlight_matched_day(row):
                        if clicked_day_from_cal is not None and row['Day'] == clicked_day_from_cal:
                            return ['background-color: #FFF9C4; color: black; border: 2px solid #FBC02D'] * len(row)
                        return [''] * len(row)

                    st.dataframe(
                        m_df[['Day', 'DETECT_DATE_STR', 'CVE_NAME', 'SEVERITY']].style.apply(highlight_matched_day, axis=1),
                        use_container_width=True, hide_index=True,
                        on_select="rerun", selection_mode="multi-row",
                        key=list_key,
                        height=300
                    )
                
                selected_days_from_list = []
                if list_key in st.session_state and st.session_state[list_key].selection.rows:
                    sel_indices = st.session_state[list_key].selection.rows
                    valid_idx = [i for i in sel_indices if i < len(m_df)]
                    selected_days_from_list = m_df.iloc[valid_idx]['Day'].unique().tolist()

                with c_cal:
                    st.markdown(f"###### {m_name} Overview (Clickable)")
                    
                    text_labels = grid_df.apply(lambda r: str(r['Day']), axis=1)
                    
                    shapes = []
                    for d_hl in selected_days_from_list:
                        d_info = grid_df[grid_df['Day'] == d_hl]
                        if not d_info.empty:
                            w, wd = d_info.iloc[0]['Week'], d_info.iloc[0]['Weekday']
                            shapes.append(dict(type="rect", x0=wd-0.5, x1=wd+0.5, y0=w-0.5, y1=w+0.5, line=dict(color="#FBC02D", width=4), fillcolor="rgba(0,0,0,0)"))

                    fig_mosaic = go.Figure(data=go.Heatmap(
                        x=grid_df['Weekday'], y=grid_df['Week'], z=grid_df['Count'],
                        text=text_labels, texttemplate="%{text}", textfont={"size": 12},
                        colorscale="Greys", showscale=False, xgap=3, ygap=3,
                        hoverinfo='z+text'
                    ))
                    
                    fig_mosaic.update_layout(
                        height=300, margin=dict(l=10,r=10,t=10,b=10),
                        xaxis=dict(tickmode='array', tickvals=[0,1,2,3,4,5,6], ticktext=['Mon','Tue','Wed','Thu','Fri','Sat','Sun'], side='top', fixedrange=True),
                        yaxis=dict(autorange='reversed', showticklabels=False, fixedrange=True),
                        shapes=shapes, clickmode='event+select', dragmode=False
                    )
                    
                    st.plotly_chart(fig_mosaic, use_container_width=True, on_select="rerun", key=cal_key)
                    
                    if clicked_day_from_cal:
                        st.caption(f"ğŸ“… Filtered Day: {clicked_day_from_cal}")

# TAB 3: Statistics
with tab3:
    st.header("Top Vulnerabilities & Matching", help="ë‚´ë¶€ ìµœë‹¤ ì·¨ì•½ì ê³¼ ì™¸ë¶€ ì¤‘ìš” ì·¨ì•½ì ì„ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    c1, c2 = st.columns(2)
    with c1:
        st.subheader("Internal Top Detected", help="ìš°ë¦¬ ì„œë²„ì—ì„œ ê°€ì¥ ë§ì´ ë°œê²¬ëœ ìƒìœ„ 10ê°œ ì·¨ì•½ì ì…ë‹ˆë‹¤.")
        internal_top = filtered_df['CVE_NAME'].value_counts().head(10).reset_index()
        internal_top.columns = ['CVE', 'Count']
        st.dataframe(internal_top, use_container_width=True, hide_index=True)
        
    with c2:
        st.subheader("Global NVD Top 10 Matching", help="ì „ ì„¸ê³„ì ìœ¼ë¡œ ìœ„í—˜í•œ ì·¨ì•½ì ì´ ë‚´ ì„œë²„ì—ë„ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.")
        internal_cves = set(filtered_df['CVE_NAME'].unique())
        nvd_rows = []
        for item in GLOBAL_TOP_10:
            cve = item['id']
            status = "Detected" if cve in internal_cves else "Safe"
            nvd_rows.append({"CVE": cve, "Description": item['desc'], "Status": status})
        
        nvd_df = pd.DataFrame(nvd_rows)
        st.dataframe(
            nvd_df, 
            column_config={
                "Status": st.column_config.TextColumn("Status", help="Detected = Action Required")
            },
            use_container_width=True, hide_index=True
        )

# TAB 4: Comparison
with tab4:
    st.header("Vulnerability Comparison", help="ë‘ ê°œì˜ ì·¨ì•½ì ì„ ì„ íƒí•˜ì—¬ ìƒì„¸ ìŠ¤í™ì„ ë¹„êµí•©ë‹ˆë‹¤.")
    col_sel, col_viz = st.columns([1, 2])
    cves = filtered_df['CVE_NAME'].unique()
    idx_a, idx_b = 0, min(1, len(cves)-1)
    
    if len(st.session_state.selected_cves) >= 1: 
        try: idx_a = list(cves).index(st.session_state.selected_cves[-1])
        except: idx_a = 0
    
    with col_sel:
        v_a = st.selectbox("Select A", cves, index=idx_a, key='va')
        v_b = st.selectbox("Select B", cves, index=idx_b, key='vb')
    
    with col_viz:
        if v_a and v_b:
            d_a = filtered_df[filtered_df['CVE_NAME'] == v_a].iloc[0]
            d_b = filtered_df[filtered_df['CVE_NAME'] == v_b].iloc[0]
            comp_data = pd.DataFrame({
                'Metric': ['CVSS', 'EPSS (x10)'],
                f'{v_a}': [d_a['CVSS_SCORE'], d_a['EPSS_SCORE']*10],
                f'{v_b}': [d_b['CVSS_SCORE'], d_b['EPSS_SCORE']*10]
            }).melt(id_vars='Metric', var_name='CVE', value_name='Value')
            
            fig_comp = px.bar(
                comp_data, x='Metric', y='Value', color='CVE', barmode='group',
                color_discrete_sequence=['#D32F2F', '#757575'], height=300,
                text_auto='.1f'
            )
            fig_comp.update_traces(textposition='outside')
            st.plotly_chart(fig_comp, use_container_width=True)
            
            st.table(pd.DataFrame({
                "Item": ["Product", "Severity", "NVD Searches"], 
                f"{v_a}": [d_a['PRODUCT_NAME'], d_a['SEVERITY'], d_a['NVD_SEARCHES']], 
                f"{v_b}": [d_b['PRODUCT_NAME'], d_b['SEVERITY'], d_b['NVD_SEARCHES']]
            }))
            st.caption("â„¹ï¸ NVD Searches: í•´ë‹¹ ì·¨ì•½ì ì— ëŒ€í•œ ëŒ€ì¤‘ì˜ ê´€ì‹¬ë„(ê²€ìƒ‰ëŸ‰)ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œì…ë‹ˆë‹¤.")

# TAB 5: Deep Analysis
with tab5:
    st.header("Deep Vulnerability Analysis", help="ë‹¨ì¼ ì·¨ì•½ì ì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„ ë° ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ì…ë‹ˆë‹¤.")
    
    if len(st.session_state.selected_cves) >= 1: 
        try:
            target_index = list(cves).index(st.session_state.selected_cves[-1])
        except ValueError:
            target_index = 0
    else:
        target_index = 0

    target_cve = st.selectbox("Select Vulnerability", cves, index=target_index)
    
    if target_cve:
        info = filtered_df[filtered_df['CVE_NAME'] == target_cve].iloc[0]
        col_main, col_gauge = st.columns([2, 1])

        with col_main:
            st.markdown(f"## {target_cve}")
            st.markdown(f"Product: {info['PRODUCT_NAME']} | Port: {info['PORT']}")
            st.info(info['DESCRIPTION'])
            
            with st.expander("ì‚¬ìš© ê°€ì´ë“œ ë° DB ì„¤ëª…"):
                st.write("1) ì•„ë˜ Exploit-DB ì¡°íšŒ ë²„íŠ¼ìœ¼ë¡œ ê³µê°œ PoC ì •ë³´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.")
                st.write("2) í•„ìš”í•˜ë©´ NVD ê³µì‹ í˜ì´ì§€ì™€ AI ë¶„ì„ ë²„íŠ¼ìœ¼ë¡œ ì¶”ê°€ ì •ë³´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.")
                st.write("â€» ì‹¤ì œ ìµìŠ¤í”Œë¡œì‡ ì½”ë“œëŠ” Exploit-DB ì‚¬ì´íŠ¸ì—ì„œ ì§ì ‘ í™•ì¸í•˜ë„ë¡ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.")

            # ---- Exploit-DB ì¡°íšŒ ì„¹ì…˜ ----
            st.markdown("### ğŸ” Exploit-DB Online Lookup")
            if st.button("Search Exploit-DB", key="btn_exploitdb",
                         help="Exploit-DBì—ì„œ ì´ CVEì— ëŒ€í•œ PoC/ìµìŠ¤í”Œë¡œì‡ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."):
                with st.spinner(f"Searching Exploit-DB for {target_cve} ..."):
                    exploits = fetch_exploitdb_for_cve(target_cve)

                if not exploits:
                    st.warning("Exploit-DB ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ ë˜ëŠ” í•´ë‹¹ CVE ë¯¸ë“±ë¡ ê°€ëŠ¥ì„±)")
                else:
                    df_edb = pd.DataFrame(exploits)
                    st.dataframe(
                        df_edb[["edb_id", "title", "date", "verified"]],
                        hide_index=True,
                        width="stretch"
                    )

                    # ìƒìœ„ ëª‡ ê°œëŠ” ë°”ë¡œ ì—´ ìˆ˜ ìˆëŠ” ë§í¬ ë²„íŠ¼ ì œê³µ
                    st.caption("ìƒìœ„ Exploit-DB í•­ëª© ë°”ë¡œê°€ê¸°:")
                    for row in exploits[:3]:
                        label = f"Open EDB-{row['edb_id']}: {row['title']}"
                        st.link_button(label, row["url"])

            st.markdown("---")

            # NVD ê³µì‹ í˜ì´ì§€ ë§í¬
            st.link_button(
                "View on NVD Official",
                f"https://nvd.nist.gov/vuln/detail/{target_cve}",
                help="NVD ê³µì‹ ì‚¬ì´íŠ¸ì˜ í•´ë‹¹ ì·¨ì•½ì  í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤."
            )
            
            # OpenAI ê¸°ë°˜ AI ë¶„ì„ (ì„ íƒ)
            if openai_api_key:
                if st.button("Ask AI Analyst", help="OpenAIë¥¼ í†µí•´ í•´ë‹¹ ì·¨ì•½ì ì— ëŒ€í•œ AI ë¶„ì„ì„ ìš”ì²­í•©ë‹ˆë‹¤."):
                    try:
                        client = OpenAI(api_key=openai_api_key)
                        resp = client.chat.completions.create(
                            model="gpt-3.5-turbo",
                            messages=[{"role": "user", "content": f"Explain exploit paths and mitigation for {target_cve}."}]
                        )
                        st.success(resp.choices[0].message.content)
                    except Exception as e:
                        st.error(str(e))

            # í˜„ì¬ CVE ì •ë³´ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ
            single_df = pd.DataFrame([info])
            excel_data = to_excel(single_df)
            if excel_data:
                st.download_button(
                    "Report Download (Excel)",
                    data=excel_data,
                    file_name=f"{target_cve}.xlsx",
                    help="í˜„ì¬ ë³´ê³  ìˆëŠ” ì·¨ì•½ì  ì •ë³´ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."
                )
        
        with col_gauge:
            color_g = "#D32F2F" if info['SEVERITY'] == 'Critical' else ("#FBC02D" if info['SEVERITY'] == 'High' else "#757575")
            fig_donut = go.Figure(
                data=[
                    go.Pie(
                        labels=['Score', 'Safe Margin'],
                        values=[info['CVSS_SCORE'], 10 - info['CVSS_SCORE']],
                        hole=.7,
                        marker_colors=[color_g, '#E0E0E0']
                    )
                ]
            )
            fig_donut.update_layout(
                height=250,
                showlegend=False,
                annotations=[dict(text=str(info['CVSS_SCORE']), x=0.5, y=0.5, font_size=20, showarrow=False)]
            )
            st.plotly_chart(fig_donut, use_container_width=True)

# TAB 6: Remediation
with tab6:
    st.header("Action Plan & Status Matrix", help="ì¡°ì¹˜ ê³„íšì„ ìˆ˜ë¦½í•˜ê³  ì§„í–‰ ìƒí™©ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.")
    with st.expander("ì‚¬ìš© ê°€ì´ë“œ ë° í™œìš©ë²•"):
        st.write("""
        ì´ íƒ­ì€ ë°œê²¬ëœ ì·¨ì•½ì ì˜ ì¡°ì¹˜ ìƒíƒœë¥¼ ì¶”ì í•˜ê³  ê´€ë¦¬í•˜ëŠ” ê³µê°„ì…ë‹ˆë‹¤.
        
        í™œìš© ë°©ë²•:
        1. ìƒíƒœ ë³€ê²½: ì•„ë˜ í‘œì—ì„œ Status(ì§„í–‰ ìƒíƒœ)ì™€ Priority(ìš°ì„ ìˆœìœ„)ë¥¼ í´ë¦­í•˜ì—¬ ë³€ê²½í•©ë‹ˆë‹¤.
        2. ë‹´ë‹¹ì ì§€ì •: Owner ì»¬ëŸ¼ì— ë‹´ë‹¹ì ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.
        3. ì§„ì²™ë„ í™•ì¸: í‘œ ì•„ë˜ì˜ ë§¤íŠ¸ë¦­ìŠ¤ ì°¨íŠ¸ì—ì„œ ìƒ‰ìƒ ë³€í™”ë¥¼ í†µí•´ ì „ì²´ì ì¸ ì¡°ì¹˜ í˜„í™©ì„ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤. (ë¹¨ê°•: ì‹œì‘ ì „, ë…¸ë‘: ì§„í–‰ ì¤‘, íšŒìƒ‰: ì™„ë£Œ)
        4. ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ: Download Plan ë²„íŠ¼ì„ ëˆŒëŸ¬ í˜„ì¬ ê³„íšì„ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ ë³´ê³ ìš©ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        """)

    current_plan = st.session_state.plan_data
    edited_plan = st.data_editor(
        current_plan,
        column_config={
            "Status": st.column_config.SelectboxColumn("Status", options=["Open", "In Progress", "Resolved", "Risk Accepted"], required=True),
            "Priority": st.column_config.SelectboxColumn("Priority", options=["Critical", "High", "Medium", "Low"], required=True),
            "Owner": st.column_config.TextColumn("Owner"),
            "Note": st.column_config.TextColumn("Note")
        },
        use_container_width=True, num_rows="fixed", key="plan_editor"
    )
    st.session_state.plan_data = edited_plan
    
    st.divider()
    st.subheader("Status Matrix (Product vs CVE)", help="ì¡°ì¹˜ ì§„í–‰ ìƒí™©ì„ ë§¤íŠ¸ë¦­ìŠ¤ í˜•íƒœë¡œ í•œëˆˆì— ë³´ì—¬ì¤ë‹ˆë‹¤.")
    
    fig_mat = px.scatter(
        edited_plan, x="PRODUCT_NAME", y="CVE_NAME",
        color="Status", color_discrete_map=STATUS_COLORS,
        title="Remediation Status Overview",
        size='CVSS_SCORE', size_max=15
    )
    fig_mat.update_traces(marker=dict(line=dict(width=1, color='white'), opacity=0.9))
    fig_mat.update_layout(
        height=600,
        xaxis=dict(showgrid=True, gridcolor='#F5F5F5'),
        yaxis=dict(showgrid=True, gridcolor='#F5F5F5', type='category'),
        paper_bgcolor="rgba(0,0,0,0)", plot_bgcolor="rgba(0,0,0,0)"
    )
    st.plotly_chart(fig_mat, use_container_width=True)
    
    excel_plan = to_excel(edited_plan)
    if excel_plan:
        st.download_button("Download Plan", data=excel_plan, file_name="plan.xlsx", help="í˜„ì¬ ì‘ì„±ëœ ì¡°ì¹˜ ê³„íšì„ ì—‘ì…€ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.")

# TAB 7: FAQ
with tab7:
    st.header("FAQ")
    st.markdown("ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤.")
    
    # [ìˆ˜ì •] About Project ì´ë™
    with st.expander("ê°œë°œ ëª©ì  ë° ì‚¬ìš© ëŒ€ìƒ"):
        st.markdown("""
        **ê°œë°œ ëª©ì **
        - ì„œë²„ ë³´ì•ˆ ì·¨ì•½ì ì˜ ì‹œê°ì  ì‹ë³„ ë° ë¶„ì„
        - ë°ì´í„° ê¸°ë°˜ì˜ ë³´ì•ˆ ì¡°ì¹˜ ìš°ì„ ìˆœìœ„ ê²°ì •
        
        **ì‚¬ìš© ëŒ€ìƒ**
        - ë³´ì•ˆ ë‹´ë‹¹ì, ì‹œìŠ¤í…œ ê´€ë¦¬ì, ëª¨ì˜í•´í‚¹ ì „ë¬¸ê°€
        """)
        
    with st.expander("Q. ì·¨ì•½ì  ìŠ¤ìº”ì€ ì–´ë–»ê²Œ ì‹¤í–‰í•˜ë‚˜ìš”?"):
        st.write("A. ì‚¬ì´ë“œë°”ì˜ Scanner Settingsì—ì„œ ë°ëª¨ ëª¨ë“œ ë˜ëŠ” ì‹¤ì œ OS í™˜ê²½ì— ë§ëŠ” ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    with st.expander("Q. ì¡°ì¹˜ ìƒíƒœë¥¼ ë³€ê²½í•˜ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"):
        st.write("A. Remediation íƒ­ì˜ í‘œì—ì„œ ìƒíƒœë¥¼ ë³€ê²½í•˜ë©´, ì•„ë˜ ë§¤íŠ¸ë¦­ìŠ¤ ê·¸ë˜í”„ì˜ ì  ìƒ‰ìƒì´ ì‹¤ì‹œê°„ìœ¼ë¡œ ë³€ê²½ë˜ì–´ ì§„ì²™ë„ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    with st.expander("Q. ìƒ‰ìƒì€ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ë‚˜ìš”?"):
        st.write("A. ë¹¨ê°•ì€ Critical, ë…¸ë‘ì€ High, íšŒìƒ‰ì€ ê·¸ ì™¸ì˜ ìœ„í—˜ë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.")
    with st.expander("Q. ë‹¤ì¤‘ ì„ íƒ ê¸°ëŠ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?"):
        st.write("A. ëŒ€ì‹œë³´ë“œ ëª©ë¡ì—ì„œ Ctrl í‚¤ë¥¼ ëˆ„ë¥´ê³  ì—¬ëŸ¬ í•­ëª©ì„ ì„ íƒí•˜ë©´, ëª¨ë“  ê·¸ë˜í”„ì—ì„œ í•´ë‹¹ í•­ëª©ë“¤ì´ ë™ì‹œì— ê°•ì¡° í‘œì‹œë©ë‹ˆë‹¤.")
    with st.expander("Q. NVD ê²€ìƒ‰ì€ ë¬´ì—‡ì¸ê°€ìš”?"):
        st.write("A. Deep Analysis íƒ­ì—ì„œ NVD ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ë¯¸êµ­ êµ­ë¦½ì·¨ì•½ì ë°ì´í„°ë² ì´ìŠ¤(NVD)ì˜ í•´ë‹¹ CVE í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
